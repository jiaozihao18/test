大模型兴起以来，推荐系统逐渐分化出两条路线。一条是**把传统推荐模型继续做大**：沿用基于学习的嵌入模型（LEM）的基本思路，将核心网络换为 Transformer 及其变体，借助更强的序列建模和更好的扩展性提升效果。另一条更激进，**将推荐直接视为 token 级别的生成任务**，用序列到序列（seq2seq）完成“检索 + 推荐”。

在第一条路线中，研究主要围绕**用户行为序列建模**和**特征交互**展开。早期用 RNN、CNN 做序列；后来各类特征交互模块增多；近年来 Transformer 成为主流，用统一长序列承载用户历史与各类特征，在大规模数据上扩展性更好。例如 Meta 的 HSTU 用 Transformer 栈与更长序列建模用户行为与特征，支撑更大参数规模并验证了生成式推荐的 scaling law。美团在 HSTU 基础上做了落地，提出 **MTGR**：保留传统推荐中的深度特征体系（含交叉特征），同时用 Transformer 统一多序列建模，兼顾效果与落地效率。

不过这些方法在结构和训练上再“像大模型”，本质仍离不开传统推荐的核心假设：**大量离散特征都需经 embedding 表映射为向量**。模型规模因此始终被 embedding 表主导，内存与参数开销大，在冷启动、新物品、跨域泛化等场景下也存在天然局限。第二条路线则**放弃“大 embedding 表”**：将离散特征（尤其是 item）改为**紧凑的 token 序列**作为输入。TIGER 用 **Semantic ID** 表示 item，以 token 序列替代传统 embedding ID；LC-Rec 将语言模型语义与协同过滤信号**对齐**；OneRec 等进一步引入**强化学习与偏好对齐**，用于多目标乃至 platform 级策略（如 CTR/CVR 与推荐质量综合优化）。

### 本文关注的问题

后文围绕下面几个问题展开：先介绍 llm4rec 的任务构建与能力，再逐节讨论实验与分析。

1. **生成式推荐模型能力由训练任务决定**：模型具备哪些能力，与任务设计有何关系？
2. **序列预测准确度**：模型规模与层级语义 ID 下的前缀匹配指标对序列预测效果有何影响？
3. **多任务能力跷跷板**：引入推荐理由、兴趣问答等多任务后，是否会拉低序列推荐准确率？任务配比与数据扩增应如何设计？
4. **与序列模型的对比与评估方式**：与 SASRec、Bert4Rec 等相比效果如何？如何用裁判模型补充评估？
5. **Token-level loss 与训练集表现**：为何 loss 已较低时训练集序列准确率仍不理想？小模型与大模型有何差异？
6. **冷启动与无效 SID**：模型是否会频繁生成训练集外或长尾 SID？前缀约束解码如何权衡？

### llm4rec 任务构建方案

语义 ID 模型训练完成后，以 Qwen3 1.7B 为基座，整体流程类似“扩词表再微调”，主要增加基于语义 ID 的 token 词表。为促进语义 ID 与文本 token 的融合，采用三阶段训练：Stage 1 仅训练新增词表的 embedding，Stage 2 做增量预训练，Stage 3 做指令微调。

**Stage 1**：扩展模型 embedding，只训练新增参数，学习率设为 1e-3，训练固定步数。**Stage 2**：放开全部参数，学习率降至 2e-5，训练 3 个 epoch。预训练包含两类任务：（1）**语义锚定**——给定语义 ID（商品 ID），让模型生成包含标题、类型、剧情的完整描述，将离散 ID 锚定到可理解的语义空间；（2）**属性映射**——将语义 ID 分别映射到**标题、类型、剧情**等单一属性（sid→title / category / plot），强化模型对 ID 与属性对应关系的记忆。此外通过随机模板生成多样化表述，提升模型对同一语义不同表述的鲁棒性。示例如下：

```python
{"text": "商品<|sid_start|><|sid_112|><|sid_267|><|sid_645|><|sid_768|><|sid_end|>是一部题材和风格涵盖喜剧、音乐与表演、其他等类型的电影，电影名称是《Hee Haw：经典回顾》。内容简介：这是一部汇集了早期《 Hee Haw 》节目精华的收藏版，收录了系列开播以来的经典小品和搞笑片段。此外，还包含了超过100首脍炙人口的乡村音乐表演。更有与早期演员的独家访谈作为特别加赠内容，让观众重温那段欢乐时光。"}
{"text": "电影商品<|sid_start|><|sid_133|><|sid_276|><|sid_609|><|sid_768|><|sid_end|>代表的作品是《卡灵顿》，类型包括剧情、爱情、传记与历史等类型。剧情概要：影片改编自真实故事，讲述了英格兰画家多拉·卡灵顿与作家利顿·斯特雷奇之间一段复杂而悲伤的爱情。他们的关系充满了情感的波折与挑战，共同经历了那个时代特有的社会氛围和个人困境。。"}
{"text": "《灵异妙探：音乐剧》对应的电影商品是<|sid_start|><|sid_243|><|sid_421|><|sid_557|><|sid_768|><|sid_end|>，这是一部涵盖喜剧、悬疑与惊悚、音乐与表演等类型风格的电影。其核心剧情为：当一位疯狂的剧作家逃离精神病院，企图为他失败的戏剧演出复仇时，一场充满音乐的谋杀悬案就此展开。警探们将围绕一名过去被认为是“开膛手杰克”式戏剧的创作者展开调查，他的作品曾遭遇滑铁卢。"}
{"text": "商品<|sid_start|><|sid_234|><|sid_263|><|sid_668|><|sid_768|><|sid_end|>是一部题材和风格涵盖音乐与表演和纪录片的电影，电影名称是《Garbage：Mile High现场演唱会》。内容简介：这是一场由著名乐队Garbage于2012年在丹佛录制的完整现场演唱会。演出不仅收录了乐队最新专辑中的热门歌曲，也演唱了他们的经典代表作，为观众呈现了一场视听盛宴。此外，影片还包含精心制作的音乐录影带以及其他幕后花絮，让歌迷能够更深入地了解乐队的音乐世界。"}
```

**Stage 3 指令微调（SFT）** 的目标是让模型具备**序列推荐**、**生成推荐理由**以及**根据用户实时反馈调整推荐**的能力。围绕“语义 ID + 用户行为序列 + 自然语言交互”设计了一组监督任务，共九类：序列预测、用户偏好分析、推荐理由生成、兴趣类别建模、多轮对话推荐等，从单步行为预测到多轮对话决策逐步增强能力。模型既能预测用户下一步可能感兴趣的内容，也能用自然语言解释推荐理由，并根据用户正负反馈动态调整。验证集与测试集仅基于序列推荐任务构建，采用留一法（leave-one-out）划分。

**兴趣类别建模**中不直接使用原始商品类型，而是对用户历史做滑动窗口统计，从类型中提取高频类别作为用户阶段性兴趣的近似，在避免人工标注的同时反映兴趣变化。**多轮对话推荐**则基于真实用户序列构造“历史 → 推荐 → 反馈 → 再推荐”的对话，将序列中后续行为视为用户隐式反馈，使模型在训练阶段即可学习根据反馈调整推荐的交互。部分任务示例如下：

```python
================================================================================
Task: ('category_analysis') 
[system] 你是一个专业的电影商品推荐助手。
[user] 用户最近浏览了：<|sid_start|><|sid_131|><|sid_352|><|sid_638|><|sid_768|><|sid_end|>, <|sid_start|><|sid_187|><|sid_341|><|sid_541|><|sid_768|><|sid_end|>, <|sid_start|><|sid_134|><|sid_264|><|sid_680|><|sid_768|><|sid_end|>, <|sid_start|><|sid_66|><|sid_327|><|sid_663|><|sid_768|><|sid_end|>, <|sid_start|><|sid_187|><|sid_468|><|sid_713|><|sid_768|><|sid_end|>, <|sid_start|><|sid_223|><|sid_437|><|sid_730|><|sid_768|><|sid_end|>, <|sid_start|><|sid_204|><|sid_264|><|sid_721|><|sid_768|><|sid_end|>, <|sid_start|><|sid_187|><|sid_475|><|sid_762|><|sid_768|><|sid_end|>, <|sid_start|><|sid_221|><|sid_466|><|sid_539|><|sid_768|><|sid_end|>，请分析用户偏好的内容类型。
[assistant] 用户主要感兴趣的类别是：动作与冒险、犯罪与推理、剧情。
================================================================================
Task: ('category_based_recommendation') 
[system] 你是一个专业的电影商品推荐助手。
[user] 我想要看怀旧类型的作品，请给我推荐几个。
[assistant] <|sid_start|><|sid_112|><|sid_488|><|sid_703|><|sid_768|><|sid_end|>、<|sid_start|><|sid_39|><|sid_498|><|sid_703|><|sid_768|><|sid_end|>、<|sid_start|><|sid_112|><|sid_337|><|sid_569|><|sid_768|><|sid_end|>、<|sid_start|><|sid_112|><|sid_260|><|sid_751|><|sid_769|><|sid_end|>、<|sid_start|><|sid_252|><|sid_372|><|sid_603|><|sid_768|><|sid_end|>
================================================================================
Task: ('multi_turn_dialogue_category')
[system] 你是一个专业的电影商品推荐助手。
[user] 我对悲剧类型的电影很感兴趣。
[assistant] 我推荐商品<|sid_start|><|sid_133|><|sid_365|><|sid_728|><|sid_768|><|sid_end|>, 商品<|sid_start|><|sid_133|><|sid_378|><|sid_728|><|sid_768|><|sid_end|>, 商品<|sid_start|><|sid_133|><|sid_365|><|sid_629|><|sid_768|><|sid_end|>，这些都是悲剧类型的经典电影。
[user] 换一个类型吧，我想看真人秀与生活方式。
[assistant] 好的，可以换个口味。真人秀与生活方式类型的是吧，我为你推荐商品<|sid_start|><|sid_2|><|sid_390|><|sid_635|><|sid_768|><|sid_end|>《幸存者：危地马拉》, 商品<|sid_start|><|sid_206|><|sid_316|><|sid_666|><|sid_769|><|sid_end|>《周六夜现场：第五季》, 商品<|sid_start|><|sid_2|><|sid_316|><|sid_662|><|sid_768|><|sid_end|>《蛋糕大师》，这些都是真人秀与生活方式类型的优秀作品。
================================================================================
Task: ('multi_turn_dialogue_sequence')
[system] 你是一个专业的电影商品推荐助手。
[user] 我最近看了《古代外星人：第七季》, 《远古外星人》, 商品<|sid_start|><|sid_248|><|sid_440|><|sid_609|><|sid_768|><|sid_end|>，有什么推荐的吗？
[assistant] 基于你的兴趣，我推荐商品<|sid_start|><|sid_21|><|sid_368|><|sid_766|><|sid_768|><|sid_end|>，它属于纪录片和历史类型。
[user] 我不太喜欢，换一个吧。
[assistant] 没问题，基于您的浏览历史，我推荐商品<|sid_start|><|sid_32|><|sid_320|><|sid_682|><|sid_768|><|sid_end|>《太空视角下的二战》给你，它属于纪录片和历史类型。
================================================================================
Task: ('preference_analysis') 
[system] 你是一个专业的电影商品推荐助手。
[user] 根据用户的历史浏览序列：<|sid_start|><|sid_240|><|sid_410|><|sid_710|><|sid_768|><|sid_end|>, <|sid_start|><|sid_166|><|sid_343|><|sid_540|><|sid_768|><|sid_end|>, <|sid_start|><|sid_63|><|sid_502|><|sid_649|><|sid_768|><|sid_end|>，请分析该用户的兴趣偏好。
[assistant] 该用户似乎偏爱充满动作、冒险和外星生物元素的作品。
================================================================================
Task: ('recommendation_reasoning')
[system] 你是一个专业的电影商品推荐助手。
[user] 已知用户浏览记录：<|sid_start|><|sid_240|><|sid_410|><|sid_710|><|sid_768|><|sid_end|>, <|sid_start|><|sid_166|><|sid_343|><|sid_540|><|sid_768|><|sid_end|>, <|sid_start|><|sid_63|><|sid_502|><|sid_649|><|sid_768|><|sid_end|>，请给出推荐并说明理由。
[assistant] 推荐商品：<|sid_start|><|sid_131|><|sid_421|><|sid_745|><|sid_768|><|sid_end|>

推荐理由：基于用户对类似科幻冒险题材的喜好，这部作品提供了相似的紧张刺激和探索未知宇宙的体验。
================================================================================
Task: ('semantic_anchoring')
[system] 你是一个专业的电影商品推荐助手。
[user] 已知以下电影商品：<|sid_start|><|sid_112|><|sid_267|><|sid_645|><|sid_768|><|sid_end|>，请提供其详细的信息。
[assistant] 您查询的商品是《Hee Haw：经典回顾》，这是一部喜剧、音乐与表演、其他等类型的作品。作品简介：这是一部汇集了早期《 Hee Haw 》节目精华的收藏版，收录了系列开播以来的经典小品和搞笑片段。此外，还包含了超过100首脍炙人口的乡村音乐表演。更有与早期演员的独家访谈作为特别加赠内容，让观众重温那段欢乐时光。。
================================================================================
Task: ('semantic_recovery') 
[system] 你是一个专业的电影商品推荐助手。
[user] 请根据以下商品信息返回对应的商品：
电影名：Hee Haw：经典回顾
类别：喜剧、音乐与表演、其他等
简介：这是一部汇集了早期《 Hee Haw 》节目精华的收藏版，收录了系列开播以来的经典小品和搞笑片段。此外，还包含了超过100首脍炙人口的乡村音乐表演。更有与早期演员的独家访谈作为特别加赠内容，让观众重温那段欢乐时光。
[assistant] 对应的商品为：<|sid_start|><|sid_112|><|sid_267|><|sid_645|><|sid_768|><|sid_end|>
================================================================================
Task: ('sequence_prediction')  
[system] 你是一个专业的电影商品推荐助手。
[user] 基于这些商品：<|sid_start|><|sid_131|><|sid_352|><|sid_638|><|sid_768|><|sid_end|>，预测用户下一步会点开哪一个。
[assistant] <|sid_start|><|sid_187|><|sid_341|><|sid_541|><|sid_768|><|sid_end|>
```

各子任务数量分布如下，SFT 数据共约 62 万条：

![](https://clouddocs.huawei.com/koopage/v1/app/api/documents/doc/preview/db0c77cf-5019-41b2-a49d-ae3228f51601?document_id=79ae59ad-8506-4a9c-8f75-506f1bd0f245 "")

### 生成式推荐模型能力由训练任务决定（问题 1）

**问题 1**：模型具备哪些能力，与任务设计有何关系？

按上述流程训练后的 Qwen3 1.7B 具备序列预测、主题推荐与多轮对话能力。训练阶段使用了多种 prompt，模型对 prompt 表述有一定鲁棒性：在意思相近、表述略有变化时，仍能保持正确的推荐输出格式。例如：

```python
USER：我看了：<|sid_start|><|sid_173|><|sid_410|><|sid_722|><|sid_768|><|sid_end|>, <|sid_start|><|sid_75|><|sid_452|><|sid_736|><|sid_768|><|sid_end|>，推荐一下。
ASSISTANT: <|sid_start|><|sid_248|><|sid_338|><|sid_646|><|sid_768|><|sid_end|><|im_end|>

USER：基于这些商品：<|sid_start|><|sid_173|><|sid_410|><|sid_722|><|sid_768|><|sid_end|>, <|sid_start|><|sid_75|><|sid_452|><|sid_736|><|sid_768|><|sid_end|>，预测用户下一步会点开哪一个。
ASSISTANT:<|sid_start|><|sid_248|><|sid_338|><|sid_646|><|sid_768|><|sid_end|><|im_end|>

(为了直观显示，将模型输出的SID转化为商品标题)
USER: 基于这些商品："黑兰花"，预测用户下一步会点开哪一个，并给出推荐理由。
ASSISTANT: 推荐："最美好的时光" \n 理由：鉴于用户对探讨情感深度和人生选择的电影感兴趣，这部影片提供了一个关于时间和情感羁绊的深刻视角，能够引起用户的共鸣。

```

在主题推荐场景下，模型可根据类型关键词进行推荐（下例中已将模型输出的 SID 转为商品标题以便阅读）：

```vb
USER: 我喜欢看动物类型的电影
ASSISTANT: "传奇白马"、"狂野巴西：火与洪之歌"、"海豚的故事2"、"马歇尔的奇迹"、"地球脉动：猎与被猎"

USER: 能给我推荐一些浪漫主题的电影吗
ASSISTANT: "无法抗拒的蓝莓农场"、"尼古拉斯·斯帕克斯浪漫电影集"、"圣诞皇冠"、"红磨坊"、"罗马假日姐妹花"
```

在多轮对话中，模型能根据用户偏好持续给出推荐：

```vb
USER: 我最近看了《但丁的地狱：动画史诗》, 《金刚狼与X战警：全集》, 商品"死亡空间：坠落"，有什么推荐的吗？
ASSISTANT: "死侍"
USER: 不错，再推荐一些类似的
ASSISTANT: 商品《死侍》是动作与冒险、喜剧、科幻与奇幻等类型的电影，很高兴你喜欢！那我再为你推荐一部相同类型的商品"鸦片与功夫大师"《街头霸王：暗杀之道》，它也是一部动作与冒险、剧情、犯罪与推理等类型的电影。
USER: 我不太喜欢，换一个吧
ASSISTANT: 好的，考虑到您的浏览偏好，我推荐商品"异形附身"给你，这是一部科幻与奇幻、恐怖、动作与冒险等类型的电影。
```

在 1.7B 上的测试表明，设计特定任务可以激发模型在对应任务上的能力，但表现也高度依赖任务设计——例如过度依赖训练时的格式，回复容易显得刻板。多轮对话数据是构建对话式推荐的基础；现有工作或基于人工对话语料，或通过 LLM 构造推荐对话数据，如 [ReDial](https://arxiv.org/abs/1812.07617)、[TG-ReDial](https://arxiv.org/abs/2010.04125)、[Pearl](https://arxiv.org/abs/2403.04460)、[LLM-ReDial](https://aclanthology.org/2024.findings-acl.529/) 等，其 prompt 设计对更复杂的对话推荐有参考价值。

### 在序列预测任务上的准确度评估（问题 2）

**问题 2**：模型规模与层级语义 ID 下的前缀匹配指标对序列预测效果有何影响？

训练阶段虽包含多类任务，评估仅针对序列预测。数据按留一法划分：若用户历史序列长度为 10，则前 8 条用于训练，倒数第二条做验证，最后一条做测试。指标采用 Hit rate 与 NDCG，推理使用 beam search。

![](https://clouddocs.huawei.com/koopage/v1/app/api/documents/doc/preview/640d24a6-abbd-49ce-b835-a5c7488bb0fc?document_id=79ae59ad-8506-4a9c-8f75-506f1bd0f245 "")

从结果看，模型规模越大，序列预测在测试集上表现越好。鉴于语义 ID 的层级结构与 LLM 逐 token 解码的特性，我们额外统计了**前缀匹配**准确度：例如 Prefix@3@10 表示 beam 宽度为 10 时，预测物品前三个 SID 均正确即算正确。不要求整段 SID 完全匹配时，准确率会进一步提高，对推荐多样性以及长尾、冷启动物品也更友好。

### 多训练任务之间的能力跷跷板效应（问题 3 与问题 4）

**问题 3**：引入推荐理由、兴趣问答等多任务后，是否会拉低序列推荐准确率？任务配比与数据扩增应如何设计？**问题 4**：与 SASRec、Bert4Rec 等相比效果如何？如何用裁判模型补充评估？

为使模型具备推荐理由生成、按兴趣问答等能力，我们在任务构造时引入了多种任务。由于评估仅针对序列预测，可以观察到：额外任务的引入会对序列推荐准确率产生一定影响。

![](https://clouddocs.huawei.com/koopage/v1/app/api/documents/doc/preview/79cc7b7f-fbfb-40dd-98c8-8c53d22a7b1d?document_id=79ae59ad-8506-4a9c-8f75-506f1bd0f245 "")

图中几种设定：“1.7b”为混合所有任务的原始模型；“1.7b_Seqx3”为在原有任务基础上将序列推荐数据扩增三倍并随机打乱；“1.7b_onlySeq”为仅训练序列推荐；“1.7b_onlySeqx3”为仅训练序列推荐且数据扩增三倍。

从图中可以得到以下结论：

1. 序列推荐在原始数据集中占比已较高（约 44%），进一步提高其占比仍能提升序列预测效果。
2. 若只关注序列预测，仅训练序列任务即可取得不错效果；YouTube、淘宝等在任务构建上确实以序列为主，OpenOneRec 则朝向全能型推荐模型发展。
3. 辅助任务对序列预测有一定正向促进作用。

在纯序列推荐场景下，我们将 llm4Rec 与 SASRec、Bert4Rec 进行对比。在 RecBole 默认参数下（未对序列模型做细致超参调优），SASRec 与 Bert4Rec 在 Hit@1 上均低于 llm4Rec（分别为 0.0049 与 0.012），Hit@10 上 SASRec 可达 0.10，Bert4Rec 为 0.05。该结论随数据集而异：上述为 Amazon Review 电影子集；在乐器子集上 llm4Rec 平均优于 SASRec 与 Bert4Rec 约 20%。

在电影推荐等场景中，仅以历史序列最后一个商品作为标准答案会受序列质量影响，因此我们引入外部裁判大模型，对 llm4Rec 与序列模型的推荐结果进行打分，所用 prompt 格式如下：

```python
你是一个专业电影推荐系统评估专家。
下面是一个用户的历史观看序列（按时间顺序）：
{history}
下面是三个不同模型给出的“下一部电影”推荐：
模型A：
{text1}
模型B：
{text2}
模型C：
{text3}
请你站在“电影推荐系统”的角度，从以下方面综合打分（1–5分，5分最好）：
- 是否符合用户历史的题材与风格
- 是否在语义上与历史序列连贯
- 是否是一个合理且有吸引力的推荐
请给出 JSON 格式的输出，例如：
{{
  "模型A": 5,
  "模型B": 4,
  "模型C": 3
}}
```

从测试集中随机采样 200 条进行评估，下图给出裁判模型的评分分布，整体上 llm4Rec 的推荐效果优于序列推荐模型：

![](https://clouddocs.huawei.com/koopage/v1/app/api/documents/doc/preview/1ba92b13-c20a-42fa-b0ac-48785738483f?document_id=79ae59ad-8506-4a9c-8f75-506f1bd0f245 "")

### 基于 token 粒度的 loss 与基于 item 粒度的 loss（问题 5）

**问题 5**：为何 loss 已较低时训练集序列准确率仍不理想？小模型与大模型有何差异？

SFT 后 loss 已降至 0.8 左右，但序列预测在训练集上的表现仍不理想。下图对比了不同训练策略下，模型在序列预测训练集上的准确度（推理未使用 beam search，参数为 temperature=0.6, top_k=20, top_p=0.95）：

![](https://clouddocs.huawei.com/koopage/v1/app/api/documents/doc/preview/8dc43456-3ea7-43b0-81b9-212ee52f2956?document_id=79ae59ad-8506-4a9c-8f75-506f1bd0f245 "")

从结果看，1.7B 训练 3 个 epoch 后，正常推理时序列预测在训练集上的准确率仍偏低，尽管全局 loss 已降至约 0.75。主要原因有两点：一是每个商品对应四层 SID，训练时用 teacher-forcing 优化的是 token 级别的 loss，推理则要求整段 SID 完全匹配（exact match）；二是多任务并存时，易学任务的 loss 会主导优化，难学任务（如完整 SID 序列）学得不够充分。模型规模增至 8B 后，对 SID 的学习能力明显增强，无需扩增序列数据即可达到较高准确率。

下面对该现象做简要理论分析。以四层 SID 为例，设 ground truth 序列为 $y=(y_1, y_2, y_3, y_4)$（忽略 start/end，只看 4 个 sid token；每个 $y_t$ 是某个 sid token，例如 $y = (58, 384, 539, 768)$）。SFT 训练时的 teacher-forcing loss（只在 assistant token 上计算）为 $\mathcal{L}=-\frac{1}{4}\sum_{t=1}^4\log p_{\theta}(y_t \mid x,y_{<t})$，其中 $x$ 表示 system+user 的条件输入，$y_{<t}$ 是真实前缀。推理时用 greedy/beam 得到序列 $\hat{y}$，Hit@1 定义为 $\mathrm{Hit@1} = 1[\hat{y}=y]$，即序列级别的 0/1 指标。

为直观理解 loss 的量纲，设各位置对正确 token 的平均概率相近为 $p$，即 $p_{\theta}(y_t\mid x,y_{<t})\approx p$，则 $\mathcal{L} \approx -\log p \Rightarrow p \approx e^{-\mathcal{L}_{TF}}$。若训练集 $loss \approx 0.8$，则 $p \approx e^{-0.8} \approx 0.449$；在理想化假设下（每步独立），完整 4 步全对概率 $p(\hat{y} = y) \approx p^4 \approx 0.449^4 \approx 0.0407$，即约 4.1%。因此 loss=0.8 在 token-level 下不错，但 exact-match 在 4 步序列上会被“乘法效应”压得很低。同理 $\mathcal{L} = 1.0$ 时 $p \approx 0.367$，$0.367^4 \approx 0.018$，约 1.8%。

上述 $p^4$ 对应“乘法效应”；实际生成中还有一点：训练时第 $t$ 步条件是真实前缀 $y_{<t}$（teacher forcing），推理时是模型前缀 $\hat{y}_{<t}$（free-running）。训练优化的是 $p_{\theta}(y_t\mid x,y_{<t})$，推理真正需要的是 $p_{\theta}(y_t\mid x, \hat{y}_{<t})$。一旦前一步出错 $(\hat{y}_{t-1} \neq y_{t-1})$，后续分布可能显著漂移，错误连锁放大，形成 exposure bias。

基于上述结果可得到以下结论：对于 1.7B 等小模型，建议以序列预测任务为主；若需叠加多任务，应提高序列任务权重或增加训练轮数，使模型充分学习 SID 序列。对于 8B 等较大模型，可在序列任务基础上叠加额外任务。

### 冷启动评测（问题 6）

**问题 6**：模型是否会频繁生成训练集外或长尾 SID？前缀约束解码如何权衡？

生成式推荐在推理时逐 token 生成 SID，因此可能生成训练集中未出现的 SID（empty），或交互次数很少的商品（≤2 次）。我们对 beam 宽度为 10 时模型生成的 SID 进行归类，结果如下：

![](https://clouddocs.huawei.com/koopage/v1/app/api/documents/doc/preview/d967547c-d762-44b6-b44b-10b7e0ec279d?document_id=79ae59ad-8506-4a9c-8f75-506f1bd0f245 "")

结果表明：beam 宽度为 1 时，不会生成商品列表外的 SID；随 beam 宽度增大，模型更可能生成长尾或列表外的 SID。beam=10 时，冷启推荐概率为 8‰，说明 llm4Rec 对冷启动物品具有推荐潜力。为减少无效 SID 的生成一般可采用前缀约束解码，beam=10 下有效语义 ID 占比超过 98%；约束解码会增加推理耗时，实验中可关闭前缀约束以权衡效率。

### 思考与优化方向

做生成式推荐落地时，需明确模型定位：是作为**推荐助手**（能对话、能解释、能根据反馈调整），还是仅作**生成式召回的序列推荐模型**。淘宝的 ALGR、谷歌的 PLUM 均将 LLM 用于纯序列推荐任务，此类场景下 prompt 无需保留原 LLM 的通用能力，设计上融入用户画像、点击序列等信息，以简洁高效为主。若定位为推荐助手，训练经验表明：特定任务的引入能赋予模型相应能力，但多任务存在跷跷板效应，可能削弱序列推荐效果，且任务与 prompt 设计不当易引入人为偏见。

生成式推荐的部署往往需在现有推荐系统上做局部优化，并具备近线/实时训练能力。相较追求更高超的训练技巧与离线指标，更务实的做法是尽快上线，结合线上迭代与 A/B 实验验证效果。大模型推理时延较高，通常需采用异步与缓存等方案；近线引擎如何实时处理埋点、如何做样本与模型迭代发布等工程能力仍需加强。

序列推荐基于 next-token loss 训练，难以直接支持“一次推理输出多个推荐”的场景——虽可用 beam search 输出多个，但易导致同质商品堆叠、多样性不足。训练方式上需从单商品预测向多商品预测演进。

Beam search 推理耗时较大，叠加前缀约束后更慢，推理性能优化仍是重要方向。
